{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f7c6fcb7-5977-4a92-830f-f162eb379028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6a96d2f2-e565-42c4-8c21-5500d563c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;31marchive.zip\u001b[0m\n",
      " \u001b[01;35mLSTM-neural-network-architecture-Input-layer-consists-of-10-sequential-time-steps-10.png\u001b[0m\u001b[K\n",
      "'Next word prediction.ipynb'\n",
      " README.md\n",
      " \u001b[00;32msentence1.txt\u001b[0m\n",
      " \u001b[00;32msentences.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "85b50084-6581-4ba9-a488-23dbca3dc43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Japanese doll.\n",
      "I hear that Nancy is very pretty.\n",
      "She was too short to see over the fence.\n",
      "He told us a very exciting adventure story.\n",
      "She always speaks to him in a loud voice.\n",
      "I want more detailed information.\n",
      "I checked to make sure that he was still alive.\n",
      "I'd rather be a bird than a fish.\n",
      "Mary plays the piano.\n",
      "She did her best to help him.\n",
      "She borrowed the book from him many years ago and hasn't yet returned it.\n",
      "She wrote him a long letter, but he didn't read it.\n",
      "Please wait outside of the house.\n",
      "Two seats were vacant.\n",
      "Tom got a small piece of pie.\n",
      "She folded her handkerchief neatly.\n",
      "We have a lot of rain in June.\n",
      "I am never at home on Sundays.\n",
      "Don't step on the broken glass.\n",
      "She advised him to come back at once.\n",
      "Let me help you with your baggage.\n",
      "The book is in front of the table.\n",
      "The mysterious diary records the voice.\n",
      "The stranger officiates the meal.\n",
      "The shooter says goodbye to his love.\n",
      "A glittering gem is not enough.\n",
      "The memory we used to share is no longer coherent.\n",
      "The old apple revels in its authority.\n",
      "Rock music approaches at high velocity.\n",
      "Sixty-Four comes asking for bread.\n",
      "Abstraction is often one floor above you.\n",
      "The river stole the gods.\n",
      "Joe made the sugar cookies; Susan decorated them.\n",
      "The sky is clear; the stars are twinkling.\n",
      "The waves were crashing on the shore; it was a lovely sight.\n"
     ]
    }
   ],
   "source": [
    "# Open the file in read mode\n",
    "with open('sentence1.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Print the content of the file\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e408fb56-c7b5-4139-8635-290b0977e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in content.split(\"\\n\"):\n",
    "    # print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3152a17f-5e44-48d9-957f-25937747c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "27e57c4b-a94e-4f9f-8644-f27c6f8fc1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating object of Tokenizer\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "adf325de-3723-4b56-9125-d5fcd95755c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([content]) # it takes multiple input so pass it list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "70cffe7b-d11c-4fc0-9c5c-0a5842a5aa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'a': 2,\n",
       " 'is': 3,\n",
       " 'she': 4,\n",
       " 'to': 5,\n",
       " 'him': 6,\n",
       " 'i': 7,\n",
       " 'in': 8,\n",
       " 'of': 9,\n",
       " 'was': 10,\n",
       " 'he': 11,\n",
       " 'it': 12,\n",
       " 'at': 13,\n",
       " 'on': 14,\n",
       " 'that': 15,\n",
       " 'very': 16,\n",
       " 'voice': 17,\n",
       " 'her': 18,\n",
       " 'help': 19,\n",
       " 'book': 20,\n",
       " 'were': 21,\n",
       " 'we': 22,\n",
       " 'you': 23,\n",
       " 'this': 24,\n",
       " 'japanese': 25,\n",
       " 'doll': 26,\n",
       " 'hear': 27,\n",
       " 'nancy': 28,\n",
       " 'pretty': 29,\n",
       " 'too': 30,\n",
       " 'short': 31,\n",
       " 'see': 32,\n",
       " 'over': 33,\n",
       " 'fence': 34,\n",
       " 'told': 35,\n",
       " 'us': 36,\n",
       " 'exciting': 37,\n",
       " 'adventure': 38,\n",
       " 'story': 39,\n",
       " 'always': 40,\n",
       " 'speaks': 41,\n",
       " 'loud': 42,\n",
       " 'want': 43,\n",
       " 'more': 44,\n",
       " 'detailed': 45,\n",
       " 'information': 46,\n",
       " 'checked': 47,\n",
       " 'make': 48,\n",
       " 'sure': 49,\n",
       " 'still': 50,\n",
       " 'alive': 51,\n",
       " \"i'd\": 52,\n",
       " 'rather': 53,\n",
       " 'be': 54,\n",
       " 'bird': 55,\n",
       " 'than': 56,\n",
       " 'fish': 57,\n",
       " 'mary': 58,\n",
       " 'plays': 59,\n",
       " 'piano': 60,\n",
       " 'did': 61,\n",
       " 'best': 62,\n",
       " 'borrowed': 63,\n",
       " 'from': 64,\n",
       " 'many': 65,\n",
       " 'years': 66,\n",
       " 'ago': 67,\n",
       " 'and': 68,\n",
       " \"hasn't\": 69,\n",
       " 'yet': 70,\n",
       " 'returned': 71,\n",
       " 'wrote': 72,\n",
       " 'long': 73,\n",
       " 'letter': 74,\n",
       " 'but': 75,\n",
       " \"didn't\": 76,\n",
       " 'read': 77,\n",
       " 'please': 78,\n",
       " 'wait': 79,\n",
       " 'outside': 80,\n",
       " 'house': 81,\n",
       " 'two': 82,\n",
       " 'seats': 83,\n",
       " 'vacant': 84,\n",
       " 'tom': 85,\n",
       " 'got': 86,\n",
       " 'small': 87,\n",
       " 'piece': 88,\n",
       " 'pie': 89,\n",
       " 'folded': 90,\n",
       " 'handkerchief': 91,\n",
       " 'neatly': 92,\n",
       " 'have': 93,\n",
       " 'lot': 94,\n",
       " 'rain': 95,\n",
       " 'june': 96,\n",
       " 'am': 97,\n",
       " 'never': 98,\n",
       " 'home': 99,\n",
       " 'sundays': 100,\n",
       " \"don't\": 101,\n",
       " 'step': 102,\n",
       " 'broken': 103,\n",
       " 'glass': 104,\n",
       " 'advised': 105,\n",
       " 'come': 106,\n",
       " 'back': 107,\n",
       " 'once': 108,\n",
       " 'let': 109,\n",
       " 'me': 110,\n",
       " 'with': 111,\n",
       " 'your': 112,\n",
       " 'baggage': 113,\n",
       " 'front': 114,\n",
       " 'table': 115,\n",
       " 'mysterious': 116,\n",
       " 'diary': 117,\n",
       " 'records': 118,\n",
       " 'stranger': 119,\n",
       " 'officiates': 120,\n",
       " 'meal': 121,\n",
       " 'shooter': 122,\n",
       " 'says': 123,\n",
       " 'goodbye': 124,\n",
       " 'his': 125,\n",
       " 'love': 126,\n",
       " 'glittering': 127,\n",
       " 'gem': 128,\n",
       " 'not': 129,\n",
       " 'enough': 130,\n",
       " 'memory': 131,\n",
       " 'used': 132,\n",
       " 'share': 133,\n",
       " 'no': 134,\n",
       " 'longer': 135,\n",
       " 'coherent': 136,\n",
       " 'old': 137,\n",
       " 'apple': 138,\n",
       " 'revels': 139,\n",
       " 'its': 140,\n",
       " 'authority': 141,\n",
       " 'rock': 142,\n",
       " 'music': 143,\n",
       " 'approaches': 144,\n",
       " 'high': 145,\n",
       " 'velocity': 146,\n",
       " 'sixty': 147,\n",
       " 'four': 148,\n",
       " 'comes': 149,\n",
       " 'asking': 150,\n",
       " 'for': 151,\n",
       " 'bread': 152,\n",
       " 'abstraction': 153,\n",
       " 'often': 154,\n",
       " 'one': 155,\n",
       " 'floor': 156,\n",
       " 'above': 157,\n",
       " 'river': 158,\n",
       " 'stole': 159,\n",
       " 'gods': 160,\n",
       " 'joe': 161,\n",
       " 'made': 162,\n",
       " 'sugar': 163,\n",
       " 'cookies': 164,\n",
       " 'susan': 165,\n",
       " 'decorated': 166,\n",
       " 'them': 167,\n",
       " 'sky': 168,\n",
       " 'clear': 169,\n",
       " 'stars': 170,\n",
       " 'are': 171,\n",
       " 'twinkling': 172,\n",
       " 'waves': 173,\n",
       " 'crashing': 174,\n",
       " 'shore': 175,\n",
       " 'lovely': 176,\n",
       " 'sight': 177}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index # now check number assigned to every word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "51d07d02-ed26-454a-81ce-3f1f066f56c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "784c1275-bcab-4c54-87d1-62188e516700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_sentence = [] # just for understanding i am making list\n",
    "# list_of_tokens = []\n",
    "# for sentence in content.split(\"\\n\"):\n",
    "#     list_of_sentence.append(sentence)\n",
    "#     tokenizer.texts_to_sequences([sentence])\n",
    "#     list_of_tokens.append(tokenizer.texts_to_sequences([sentence]))\n",
    "#     print(tokenizer.texts_to_sequences([sentence])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4479c314-f96d-4869-af53-fa426c7fce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ist_of_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e5a9cf89-1753-4468-a690-2b2b781ab67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c23e0902-5904-43a0-ab10-db40d3678e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 1\n",
    "input_sentences = []\n",
    "counter = 0\n",
    "for sentence in content.split(\"\\n\"):\n",
    "    counter = counter+1 \n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for start in range(1, len(tokenized_sentence)):\n",
    "        final = tokenized_sentence[:start+end]\n",
    "        input_sentences.append(final)\n",
    "        #print(final) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "31fa2a02-079d-4f69-983d-fc459d70578d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter # totel lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b3f456eb-4e07-41f1-9c59-425913a79e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_length = max([len(sentence) for sentence in input_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9707bed1-27c3-4b47-b8fc-76c0241b43c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f5fca53d-d70a-42c4-b262-02d26f2f99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "683b12b5-9542-4926-ab34-98d7030554a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_text = pad_sequences(input_sentences, maxlen = maximum_length, padding= \"pre\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3a2ddd37-ed71-42ba-b5ef-fad47cfb364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  24,   3],\n",
       "       [  0,   0,   0, ...,  24,   3,   2],\n",
       "       [  0,   0,   0, ...,   3,   2,  25],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  12,  10,   2],\n",
       "       [  0,   0,   0, ...,  10,   2, 176],\n",
       "       [  0,   0,   1, ...,   2, 176, 177]], dtype=int32)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0ada14ad-6c49-46d3-b682-ac2e65f9c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now build dataset\n",
    "X = padded_text[:,:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "dfe7974e-2c50-418c-8d7d-a66fd04b8a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,  24],\n",
       "       [  0,   0,   0, ...,   0,  24,   3],\n",
       "       [  0,   0,   0, ...,  24,   3,   2],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 175,  12,  10],\n",
       "       [  0,   0,   0, ...,  12,  10,   2],\n",
       "       [  0,   0,   1, ...,  10,   2, 176]], dtype=int32)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7ff633c0-73e9-4a7e-a075-17700409cda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 13)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "267096c7-d927-4d28-8f60-958cc1efb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = padded_text[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "443311b5-7ef6-4956-9f35-be73d0dee3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   2,  25,  26,  27,  15,  28,   3,  16,  29,  10,  30,  31,\n",
       "         5,  32,  33,   1,  34,  35,  36,   2,  16,  37,  38,  39,  40,\n",
       "        41,   5,   6,   8,   2,  42,  17,  43,  44,  45,  46,  47,   5,\n",
       "        48,  49,  15,  11,  10,  50,  51,  53,  54,   2,  55,  56,   2,\n",
       "        57,  59,   1,  60,  61,  18,  62,   5,  19,   6,  63,   1,  20,\n",
       "        64,   6,  65,  66,  67,  68,  69,  70,  71,  12,  72,   6,   2,\n",
       "        73,  74,  75,  11,  76,  77,  12,  79,  80,   9,   1,  81,  83,\n",
       "        21,  84,  86,   2,  87,  88,   9,  89,  90,  18,  91,  92,  93,\n",
       "         2,  94,   9,  95,   8,  96,  97,  98,  13,  99,  14, 100, 102,\n",
       "        14,   1, 103, 104, 105,   6,   5, 106, 107,  13, 108, 110,  19,\n",
       "        23, 111, 112, 113,  20,   3,   8, 114,   9,   1, 115, 116, 117,\n",
       "       118,   1,  17, 119, 120,   1, 121, 122, 123, 124,   5, 125, 126,\n",
       "       127, 128,   3, 129, 130, 131,  22, 132,   5, 133,   3, 134, 135,\n",
       "       136, 137, 138, 139,   8, 140, 141, 143, 144,  13, 145, 146, 148,\n",
       "       149, 150, 151, 152,   3, 154, 155, 156, 157,  23, 158, 159,   1,\n",
       "       160, 162,   1, 163, 164, 165, 166, 167, 168,   3, 169,   1, 170,\n",
       "       171, 172, 173,  21, 174,  14,   1, 175,  12,  10,   2, 176, 177],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "432ff5ec-a9f1-476a-98a8-cde8f91b6d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 178, 178)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4b7d904c-abc9-4bf8-aa97-e288eb9332c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_classes = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "814423d2-7e5e-4cd9-8f61-2fa1aa196a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y, num_classes = total_classes + 1) # total_classes are value in vocab and index start form 1 so last will not be count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7cad732f-1684-4b9f-aa27-6df7dd24c201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 178, 178, 178)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "be77e6f1-258d-4e71-893f-552d7779e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0a767b57-e22c-4ea9-b147-0b7bfb29a43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">177</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,577</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │        \u001b[38;5;34m17,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m177\u001b[0m)               │        \u001b[38;5;34m35,577\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">294,077</span> (1.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m294,077\u001b[0m (1.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">294,077</span> (1.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m294,077\u001b[0m (1.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_classes, 100, input_length = maximum_length))  # Embedding layer \n",
    "model.add(LSTM(200, return_sequences=False))  # LSTM layer\n",
    "model.add(Dense(total_classes, activation=\"softmax\"))  # Dense layer (178 are total words in vocab, activation is softmax to get probabity of every word)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Build the model with a sample input\n",
    "sample_input = np.random.randint(0, total_classes, size=(1, 50))  # Example input (batch_size=1, sequence_length=50)\n",
    "model(sample_input)\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a48af13a-0dbc-48fb-9738-77b0035f71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total words 178 and every words is getting 100 is 100 demensional vector for every word 178*100 = 17800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "34996d71-cf2d-4959-86da-30c6cc513026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 13)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0cb3c944-cc02-462a-a41d-676879772969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 178, 178, 178)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64698224-4c67-47f8-b327-7f32ae02dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc0e1b-fac7-4f23-b2a9-17e2d8554427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "text = \"She\"\n",
    "\n",
    "for i in range(10): \n",
    "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "    padded_text = pad_sequences([token_text], maxlen = maximum_length, padding= \"pre\" )\n",
    "\n",
    "    pos = np.argmax(model.predict(padded_text))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == pos:\n",
    "            text = text + \" \" + word\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa200b-ac38-4edd-bb21-4cadc1252a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e4b48-78bc-49da-9366-f7aba8f99034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44461a39-cf73-4fdc-8e4a-2e6216c2f571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
